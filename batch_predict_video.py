from tqdm import tqdm
from ultralytics import YOLO
import cv2
from pathlib import Path
import argparse

def batch_predict(video_dir: Path, output_dir: Path, project_dir: Path):
    """
    Run predictions on all video in a video directory
    using all YOLO models in a project directory
    and saves the output videos with bounding boxes.

    Directory structures:

        project_dir
        |-- model1
        |   |-- weights
        |   |   |-- best.pt
        |-- model2
        |   |-- weights
        |   |   |-- best.pt
        |-- model3
        |   |-- weights
        |   |   |-- best.pt

        VIDEOS_DIR
        |-- test-video1.mp4
        |-- test-video2.mp4

        OUTPUT_DIR (videos here are generated by this script)
        |-- test-video1_model1.mp4
        |-- test-video1_model2.mp4
        |-- test-video1_model3.mp4
        ...

    """

    test_videos = list(video_dir.glob('*.*'))

    model_paths = sorted(list(project_dir.rglob('best.pt')))
    run_names = sorted([run.name for run in project_dir.glob('*')])
    models = dict(zip(run_names, model_paths))

    total_output_videos = len(test_videos) * len(models)
    current_count = 0

    for model_name, model_path in models.items():
        for video in test_videos:
            current_count += 1
            
            output_video = output_dir / f'{video.stem}_{model_name}.mp4'
            
            if output_video.exists():
                print(f"{current_count}/{total_output_videos} Skipping {output_video.name} - already exists.")
                continue

            cap = cv2.VideoCapture(video)
            ret, frame = cap.read()
            H, W, _ = frame.shape

            out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))

            total_inference_time = 0.0
            frames = 0

            # Load a model
            model = YOLO(model_path)  # load a custom model

            threshold = 0.5

            with tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), desc=f"{current_count}/{total_output_videos} Processing {output_video.name}", unit='frames') as progress_bar:
                while ret:

                    progress_bar.update(1)

                    results = model(frame, verbose=False)[0]
                    total_inference_time += results.speed['preprocess']
                    total_inference_time += results.speed['inference']
                    total_inference_time += results.speed['postprocess']
                    frames += 1

                    # Get frame time
                    frame_time = 0.0
                    frame_time += results.speed['preprocess']
                    frame_time += results.speed['inference']
                    frame_time += results.speed['postprocess']

                    # Calculate FPS
                    fps = 1000/frame_time

                    for result in results.boxes.data.tolist():
                        x1, y1, x2, y2, score, class_id = result

                        if score > threshold:
                            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 1)
                            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 3, cv2.LINE_AA)
                    
                    # Display FPS
                    cv2.putText(frame, str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)

                    out.write(frame)
                    ret, frame = cap.read()

            print(f"Average Inference Time per frame: {total_inference_time/frames} ms")
            print(f"FPS based on Average Inference Time: {1/(total_inference_time/(frames*1000))} FPS")
            print()

            cap.release()
            out.release()

if __name__ == '__main__':
    # parse command line arguments
    parser = argparse.ArgumentParser(description="Batch predict images")
    parser.add_argument('video_dir', type=Path, help='Path to the directory containing input video files.')
    parser.add_argument('output_dir', type=Path, help='Directory to save the predicted videos with bounding boxes.')
    parser.add_argument('project_dir', type=Path, help='Project directory containing YOLO training runs')
    args = parser.parse_args()

    batch_predict(args.video_dir, args.output_dir, args.project_dir)